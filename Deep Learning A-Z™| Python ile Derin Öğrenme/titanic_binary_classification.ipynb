{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijViXjBruF5J"
      },
      "source": [
        "# TITANIC Binary Classification\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkd9dT4iuOF3"
      },
      "source": [
        "**Colab** Identity Confirmation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8d2hBYwacLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6bb44b-3eaf-4439-a7a9-feb2936dbf87"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGCNo6-pb31a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6807c584-a2c6-440c-e52f-e59f37a5c0be"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Udemy_DerinOgrenmeyeGiris/Titanic Gorsellestirme ve Siniflama\")\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Udemy_DerinOgrenmeyeGiris/Titanic Gorsellestirme ve Siniflama\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9WYuh6SuTpe"
      },
      "source": [
        "**Import dependencies..**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAy5JvXodp0J"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import re\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwrZs8WXuaiE"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrR9RZ9hdqKU"
      },
      "source": [
        "# DATA PREPROCESSING\n",
        "\n",
        "def preprocess(data):\n",
        "    \n",
        "    #Cabin\n",
        "    data.Cabin.fillna('0', inplace=True)\n",
        "    data.loc[data.Cabin.str[0] == 'A', 'Cabin'] = 1\n",
        "    data.loc[data.Cabin.str[0] == 'B', 'Cabin'] = 2\n",
        "    data.loc[data.Cabin.str[0] == 'C', 'Cabin'] = 3\n",
        "    data.loc[data.Cabin.str[0] == 'D', 'Cabin'] = 4\n",
        "    data.loc[data.Cabin.str[0] == 'E', 'Cabin'] = 5\n",
        "    data.loc[data.Cabin.str[0] == 'F', 'Cabin'] = 6\n",
        "    data.loc[data.Cabin.str[0] == 'G', 'Cabin'] = 7\n",
        "    data.loc[data.Cabin.str[0] == 'T', 'Cabin'] = 8\n",
        "    \n",
        "    # Label encoding for 'Sex'\n",
        "    data['Sex'].replace('female', 1, inplace=True)\n",
        "    data['Sex'].replace('male', 2, inplace=True)\n",
        "    \n",
        "    # One got encoding for 'Embarked'\n",
        "    data['Embarked'].replace('S', 1, inplace=True)\n",
        "    data['Embarked'].replace('C', 2, inplace=True)\n",
        "    data['Embarked'].replace('Q', 3, inplace=True)\n",
        "    \n",
        "    # Filling NA values with median for numerical variables\n",
        "    data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "    data['Fare'].fillna(data['Fare'].median(), inplace=True)\n",
        "    data['Embarked'].fillna(data['Embarked'].median(), inplace=True)\n",
        "    \n",
        "    # Alternatively, we can delete NA values\n",
        "    # data.dropna(subset=['Fare', 'Embarked'], inplace=True, how='any')\n",
        "    return data\n",
        "\n",
        "def group_titles(data):\n",
        "    data['Names'] = data['Name'].map(lambda x: len(re.split(' ', x)))\n",
        "    data['Title'] = data['Name'].map(lambda x: re.search(', (.+?) ', x).group(1))\n",
        "    data['Title'].replace('Master.', 0, inplace=True)\n",
        "    data['Title'].replace('Mr.', 1, inplace=True)\n",
        "    data['Title'].replace(['Ms.','Mlle.', 'Miss.'], 2, inplace=True)\n",
        "    data['Title'].replace(['Mme.', 'Mrs.'], 3, inplace=True)\n",
        "    data['Title'].replace(['Dona.', 'Lady.', 'the Countess.', 'Capt.', 'Col.', 'Don.', 'Dr.', 'Major.', 'Rev.', 'Sir.', 'Jonkheer.', 'the'], 4, inplace=True)\n",
        "\n",
        "def data_subset(data):\n",
        "    features = ['Pclass', 'SibSp', 'Parch', 'Sex', 'Names', 'Title', 'Age', 'Cabin'] #, 'Fare', 'Embarked']\n",
        "    lengh_features = len(features)\n",
        "    subset = data[features]#.fillna(0)\n",
        "    return subset, lengh_features\n",
        "\n",
        "def create_model(train_set_size, input_length, num_epochs, batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(7, input_dim=input_length, activation='softplus'))\n",
        "    model.add(Dense(3, activation='softplus'))\n",
        "    model.add(Dense(1, activation='softplus'))\n",
        "\n",
        "    lr = .001\n",
        "    adam0 = Adam(lr = lr)\n",
        "\n",
        "    # Save weights, if we reach a better result while compiling the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam0, metrics=['accuracy'])\n",
        "    filepath = 'weights.best.hdf5'\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    history_model = model.fit(X_train[:train_set_size], Y_train[:train_set_size], callbacks=callbacks_list, epochs=num_epochs, batch_size=batch_size, verbose=0) #40, 32\n",
        "    return model, history_model\n",
        "\n",
        "def plots(history):\n",
        "    loss_history = history.history['loss']\n",
        "    acc_history = history.history['accuracy']\n",
        "    epochs = [(i + 1) for i in range(num_epochs)]\n",
        "\n",
        "    ax = plt.subplot(211)\n",
        "    ax.plot(epochs, loss_history, color='red')\n",
        "    ax.set_xlabel('Epochs')\n",
        "    ax.set_ylabel('Error Rate\\n')\n",
        "    ax.set_title('Error Rate per Epoch\\n')\n",
        "\n",
        "    ax2 = plt.subplot(212)\n",
        "    ax2.plot(epochs, acc_history, color='blue')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('Accuracy\\n')\n",
        "    ax2.set_title('Accuracy per Epoch\\n')\n",
        "\n",
        "    plt.subplots_adjust(hspace=0.8)\n",
        "    plt.savefig('Accuracy_loss.png')\n",
        "    plt.close()\n",
        "\n",
        "def test(batch_size):\n",
        "    test = pd.read_csv('test.csv', header=0)\n",
        "    test_ids = test['PassengerId']\n",
        "    test = preprocess(test)\n",
        "    group_titles(test)\n",
        "    testdata, _ = data_subset(test)\n",
        "\n",
        "    X_test = np.array(testdata).astype(float)\n",
        "\n",
        "    output = model.predict(X_test, batch_size=batch_size, verbose=0)\n",
        "    output = output.reshape((418,))\n",
        "\n",
        "    # Instead of decimal values, results can be integerized (0-1)\n",
        "    #outputBin = np.zeros(0)\n",
        "    #for element in output:\n",
        "    #    if element <= .5:\n",
        "    #         outputBin = np.append(outputBin, 0)\n",
        "    #    else:\n",
        "    #        outputBin = np.append(outputBin, 1)\n",
        "    #output = np.array(outputBin).astype(int)\n",
        "\n",
        "    column_1 = np.concatenate((['PassengerId'], test_ids ), axis=0 )\n",
        "    column_2 = np.concatenate( ( ['Survived'], output ), axis=0 )\n",
        "\n",
        "    f = open(\"output.csv\", \"w\")\n",
        "    writer = csv.writer(f)\n",
        "    for i in range(len(column_1)):\n",
        "        writer.writerow( [column_1[i]] + [column_2[i]])\n",
        "    f.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kifsWCMnufSm"
      },
      "source": [
        "### Train and Test Operations - Graphical Presentation for Results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-Y4C4ildiOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c99be3a6-0798-43c4-e8ca-3e518bad9fe1"
      },
      "source": [
        "# To get iterative results\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "train = pd.read_csv('train.csv', header=0)\n",
        "\n",
        "\n",
        "preprocess(train)\n",
        "group_titles(train)\n",
        "\n",
        "\n",
        "num_epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "\n",
        "traindata, lengh_features = data_subset(train)\n",
        "\n",
        "Y_train = np.array(train['Survived']).astype(int)\n",
        "X_train = np.array(traindata).astype(float)\n",
        "\n",
        "\n",
        "train_set_size = int(.67 * len(X_train))\n",
        "\n",
        "\n",
        "model, history_model = create_model(train_set_size, lengh_features, num_epochs, batch_size)\n",
        "\n",
        "plots(history_model)\n",
        "\n",
        "\n",
        "X_validation = X_train[train_set_size:]\n",
        "Y_validation = Y_train[train_set_size:]\n",
        "\n",
        "\n",
        "loss_and_metrics = model.evaluate(X_validation, Y_validation, batch_size=batch_size)\n",
        "print (\"loss_and_metrics\")\n",
        "\n",
        "test(batch_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: accuracy improved from -inf to 0.60738, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: accuracy did not improve from 0.60738\n",
            "\n",
            "Epoch 00003: accuracy did not improve from 0.60738\n",
            "\n",
            "Epoch 00004: accuracy did not improve from 0.60738\n",
            "\n",
            "Epoch 00005: accuracy improved from 0.60738 to 0.65101, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: accuracy improved from 0.65101 to 0.65604, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00007: accuracy improved from 0.65604 to 0.66611, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00008: accuracy improved from 0.66611 to 0.67785, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00009: accuracy improved from 0.67785 to 0.69295, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00010: accuracy did not improve from 0.69295\n",
            "\n",
            "Epoch 00011: accuracy did not improve from 0.69295\n",
            "\n",
            "Epoch 00012: accuracy improved from 0.69295 to 0.69463, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00013: accuracy did not improve from 0.69463\n",
            "\n",
            "Epoch 00014: accuracy did not improve from 0.69463\n",
            "\n",
            "Epoch 00015: accuracy did not improve from 0.69463\n",
            "\n",
            "Epoch 00016: accuracy did not improve from 0.69463\n",
            "\n",
            "Epoch 00017: accuracy did not improve from 0.69463\n",
            "\n",
            "Epoch 00018: accuracy improved from 0.69463 to 0.71141, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00019: accuracy improved from 0.71141 to 0.71980, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00020: accuracy did not improve from 0.71980\n",
            "\n",
            "Epoch 00021: accuracy did not improve from 0.71980\n",
            "\n",
            "Epoch 00022: accuracy did not improve from 0.71980\n",
            "\n",
            "Epoch 00023: accuracy improved from 0.71980 to 0.72987, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00024: accuracy did not improve from 0.72987\n",
            "\n",
            "Epoch 00025: accuracy did not improve from 0.72987\n",
            "\n",
            "Epoch 00026: accuracy improved from 0.72987 to 0.73826, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00027: accuracy did not improve from 0.73826\n",
            "\n",
            "Epoch 00028: accuracy improved from 0.73826 to 0.73993, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00029: accuracy improved from 0.73993 to 0.74161, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00030: accuracy did not improve from 0.74161\n",
            "\n",
            "Epoch 00031: accuracy did not improve from 0.74161\n",
            "\n",
            "Epoch 00032: accuracy did not improve from 0.74161\n",
            "\n",
            "Epoch 00033: accuracy improved from 0.74161 to 0.75503, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00034: accuracy did not improve from 0.75503\n",
            "\n",
            "Epoch 00035: accuracy did not improve from 0.75503\n",
            "\n",
            "Epoch 00036: accuracy did not improve from 0.75503\n",
            "\n",
            "Epoch 00037: accuracy did not improve from 0.75503\n",
            "\n",
            "Epoch 00038: accuracy did not improve from 0.75503\n",
            "\n",
            "Epoch 00039: accuracy did not improve from 0.75503\n",
            "\n",
            "Epoch 00040: accuracy did not improve from 0.75503\n",
            "\n",
            "Epoch 00041: accuracy did not improve from 0.75503\n",
            "\n",
            "Epoch 00042: accuracy did not improve from 0.75503\n",
            "\n",
            "Epoch 00043: accuracy did not improve from 0.75503\n",
            "\n",
            "Epoch 00044: accuracy did not improve from 0.75503\n",
            "\n",
            "Epoch 00045: accuracy did not improve from 0.75503\n",
            "\n",
            "Epoch 00046: accuracy improved from 0.75503 to 0.75671, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00047: accuracy did not improve from 0.75671\n",
            "\n",
            "Epoch 00048: accuracy did not improve from 0.75671\n",
            "\n",
            "Epoch 00049: accuracy did not improve from 0.75671\n",
            "\n",
            "Epoch 00050: accuracy improved from 0.75671 to 0.75839, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00051: accuracy did not improve from 0.75839\n",
            "\n",
            "Epoch 00052: accuracy did not improve from 0.75839\n",
            "\n",
            "Epoch 00053: accuracy did not improve from 0.75839\n",
            "\n",
            "Epoch 00054: accuracy improved from 0.75839 to 0.76342, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00055: accuracy improved from 0.76342 to 0.76510, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00056: accuracy did not improve from 0.76510\n",
            "\n",
            "Epoch 00057: accuracy did not improve from 0.76510\n",
            "\n",
            "Epoch 00058: accuracy did not improve from 0.76510\n",
            "\n",
            "Epoch 00059: accuracy did not improve from 0.76510\n",
            "\n",
            "Epoch 00060: accuracy did not improve from 0.76510\n",
            "\n",
            "Epoch 00061: accuracy did not improve from 0.76510\n",
            "\n",
            "Epoch 00062: accuracy did not improve from 0.76510\n",
            "\n",
            "Epoch 00063: accuracy did not improve from 0.76510\n",
            "\n",
            "Epoch 00064: accuracy did not improve from 0.76510\n",
            "\n",
            "Epoch 00065: accuracy did not improve from 0.76510\n",
            "\n",
            "Epoch 00066: accuracy improved from 0.76510 to 0.76678, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00067: accuracy did not improve from 0.76678\n",
            "\n",
            "Epoch 00068: accuracy did not improve from 0.76678\n",
            "\n",
            "Epoch 00069: accuracy did not improve from 0.76678\n",
            "\n",
            "Epoch 00070: accuracy did not improve from 0.76678\n",
            "\n",
            "Epoch 00071: accuracy improved from 0.76678 to 0.77013, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00072: accuracy did not improve from 0.77013\n",
            "\n",
            "Epoch 00073: accuracy improved from 0.77013 to 0.77517, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00074: accuracy did not improve from 0.77517\n",
            "\n",
            "Epoch 00075: accuracy did not improve from 0.77517\n",
            "\n",
            "Epoch 00076: accuracy did not improve from 0.77517\n",
            "\n",
            "Epoch 00077: accuracy did not improve from 0.77517\n",
            "\n",
            "Epoch 00078: accuracy did not improve from 0.77517\n",
            "\n",
            "Epoch 00079: accuracy did not improve from 0.77517\n",
            "\n",
            "Epoch 00080: accuracy did not improve from 0.77517\n",
            "\n",
            "Epoch 00081: accuracy did not improve from 0.77517\n",
            "\n",
            "Epoch 00082: accuracy improved from 0.77517 to 0.77685, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00083: accuracy did not improve from 0.77685\n",
            "\n",
            "Epoch 00084: accuracy improved from 0.77685 to 0.78188, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00085: accuracy improved from 0.78188 to 0.78356, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00086: accuracy did not improve from 0.78356\n",
            "\n",
            "Epoch 00087: accuracy did not improve from 0.78356\n",
            "\n",
            "Epoch 00088: accuracy improved from 0.78356 to 0.78523, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00089: accuracy improved from 0.78523 to 0.78691, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00090: accuracy did not improve from 0.78691\n",
            "\n",
            "Epoch 00091: accuracy did not improve from 0.78691\n",
            "\n",
            "Epoch 00092: accuracy did not improve from 0.78691\n",
            "\n",
            "Epoch 00093: accuracy did not improve from 0.78691\n",
            "\n",
            "Epoch 00094: accuracy did not improve from 0.78691\n",
            "\n",
            "Epoch 00095: accuracy did not improve from 0.78691\n",
            "\n",
            "Epoch 00096: accuracy did not improve from 0.78691\n",
            "\n",
            "Epoch 00097: accuracy improved from 0.78691 to 0.79195, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00098: accuracy improved from 0.79195 to 0.79362, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00099: accuracy did not improve from 0.79362\n",
            "\n",
            "Epoch 00100: accuracy did not improve from 0.79362\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8271\n",
            "loss_and_metrics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS_ARVdJoxBQ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}